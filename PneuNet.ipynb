{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.random import set_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils.ResNet18 import *\n",
    "from utils.Image_reader import Imagereader\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set GPU Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0],True)\n",
    "print('Num GPUs Available:', len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_divice_protos = device_lib.list_local_devices()\n",
    "    # print(local_divice_protos)\n",
    "    return [x for x in local_divice_protos if x.device_type == 'GPU']\n",
    "    \n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Imagereader()\n",
    "df_train, df_test = Data.datasetGen('Kaggle_dataset', testGen = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "BS = 16\n",
    "BATCH = BS \n",
    "SEED = 42\n",
    "H = 224\n",
    "W = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df_train, test_size = 0.2, random_state = SEED, stratify = df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "                                  zoom_range = 0.1,\n",
    "                                  rotation_range = 0.1,\n",
    "                                  width_shift_range = 0.1,\n",
    "                                  height_shift_range = 0.1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "ds_train = train_datagen.flow_from_dataframe(train_df,\n",
    "                                             x_col = 'image',\n",
    "                                             y_col = 'class',\n",
    "                                             target_size = (H,W),\n",
    "                                             batch_size = BATCH,\n",
    "                                             seed = SEED)\n",
    "\n",
    "ds_val = val_datagen.flow_from_dataframe(val_df,\n",
    "                                            x_col = 'image',\n",
    "                                            y_col = 'class',\n",
    "                                            target_size = (H,W),\n",
    "                                            batch_size = BATCH,\n",
    "                                            seed = SEED)\n",
    "\n",
    "ds_test = val_datagen.flow_from_dataframe(df_test,\n",
    "                                            x_col = 'image',\n",
    "                                            y_col = 'class',\n",
    "                                            target_size = (H,W),\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build PneuNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units = projection_dim)\n",
    "        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start = 0, limit=self.num_patches, delta = 1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layers = 6\n",
    "\n",
    "num_heads = 16\n",
    "projection_dim = 80\n",
    "mlp_head_units = [1024, 64, 16]\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel  = resnet_18(input_shape=(H,W,3), nclass=2, Denselayer = False)\n",
    "\n",
    "Inputs_ = layers.Input(shape=(H, W, 3))\n",
    "x = baseModel(Inputs_)\n",
    "x = layers.MaxPool2D((2,2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "temp_shape = keras.backend.int_shape(x)\n",
    "batch_size = tf.shape(x)[0]\n",
    "patch_dim = temp_shape[1]*temp_shape[2]\n",
    "channel = temp_shape[-1]\n",
    "num_patches = channel\n",
    "print(temp_shape)\n",
    "x = tf.reshape(x,[batch_size, -1, patch_dim])\n",
    "\n",
    "encoded_patches = Encoder(num_patches, projection_dim)(x)\n",
    "for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.2\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.2)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "representation = layers.Flatten()(representation)\n",
    "representation = layers.Dropout(0.2)(representation)\n",
    "# Add MLP.\n",
    "features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.2)\n",
    "# Classify outputs.\n",
    "logits = layers.Dense(3,activation = 'softmax')(features)\n",
    "\n",
    "# Create the Keras model.\n",
    "model = keras.Model(inputs=Inputs_ , outputs=logits )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up optimizer, metric and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "weight_decay = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    " \n",
    "model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "#         checkpoint_filepath,\n",
    "#         monitor=\"val_accuracy\",\n",
    "#         save_best_only=True,\n",
    "#         save_weights_only=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "        ds_train,\n",
    "        batch_size=BS,\n",
    "        epochs=100,\n",
    "        validation_data=ds_val,\n",
    "        # callbacks=[checkpoint_callback],\n",
    "    )\n",
    "# model.load_weights(checkpoint_filepath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1e00a935d1e9941840f92dfd84d0b06a81648d31986898f7cd0b7ba9fefbeae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflow-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
